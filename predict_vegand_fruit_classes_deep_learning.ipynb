{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98facb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_path = 'Fruits_Vegetables/train'\n",
    "df_test_path = 'Fruits_Vegetables/test'\n",
    "df_val_path = 'Fruits_Vegetables/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b73a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 180 \n",
    "img_height = 180 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    df_train_path,\n",
    "    shuffle=True,\n",
    "    image_size=(img_width,img_height),\n",
    "    batch_size=32,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebed949",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    df_val_path,\n",
    "    shuffle=True,\n",
    "    image_size=(img_width,img_height),\n",
    "    batch_size=32,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    df_test_path,\n",
    "    shuffle=True,\n",
    "    image_size=(img_width,img_height),\n",
    "    batch_size=32,\n",
    "    validation_split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5614a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print some images .\n",
    "# plt.figure(figsize=(10,10)): This line creates a new figure for plotting with a size of 10x10 inches.\n",
    "\n",
    "#     In TensorFlow, datasets are often represented as sequences of elements, such\n",
    "#     as images, labels, or other data points. The take() method allows you to extract\n",
    "#     a specified number of elements from the dataset.\n",
    "    \n",
    "# for image, label in data_train.take(1):: This loop iterates over the first batch\n",
    "#         of images and labels in the data_train dataset. It appears that data_train\n",
    "#         is a TensorFlow dataset.\n",
    "\n",
    "# for i in range(9):: This nested loop iterates over the indices 0 to 8 (inclusive), \n",
    "#         indicating that nine images will be plotted in a 3x3 grid.\n",
    "\n",
    "# plt.subplot(3, 3, i+1): This line creates subplots within the figure. It specifies \n",
    "#     that the subplot grid will have 3 rows and 3 columns, and the current subplot\n",
    "#     being processed is determined by the loop index i. The i+1 is used because \n",
    "#     subplot indices start from 1, not 0.\n",
    "\n",
    "# plt.imshow(image[i].numpy().astype('uint8')): This line displays the image in the \n",
    "#     current subplot. image[i] retrieves the ith image from the batch, .numpy()\n",
    "#     converts the TensorFlow tensor to a NumPy array, and .astype('uint8')\n",
    "#     converts the pixel values to unsigned 8-bit integers, which is a common\n",
    "#     format for image data.\n",
    "\n",
    "# plt.title(data_cat[label[i]]): This line sets the title of the current subplot\n",
    "#     to the corresponding label of the image. label[i] retrieves the label of\n",
    "#     the ith image from the batch, and data_cat[label[i]] looks up the \n",
    "#     corresponding category name using the label.\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "for image,label in data_train.take(1):\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(image[i].numpy().astype('uint8'))\n",
    "        plt.title(data_cat[label[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential model .\n",
    "model = Sequential([\n",
    "#     .)rescaling img pixels.\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16,3,padding=\"same\",activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64,3,padding=\"same\",activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(128),\n",
    "    layers.Dense(len(data_cat))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab055db",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_size=25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(data_train,validation_data,data_val,epochs=epochs_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03945975",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(epochs_size)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range,history.history['accuracy'],label='Training Accuracy')\n",
    "plt.plot(epochs_range,history.history['val_accuracy'],label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range,history.history['loss'],label='Training loss')\n",
    "plt.plot(epochs_range,history.history['val_loss'],label='Validation loss')\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf786f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(epochs_size)\n",
    "epochs_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0575905",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ''\n",
    "image = tf.keras.utils.load_img(image,target_size=(img_height,img_width))\n",
    "img_arr = tf.keras.utils.array_to_img(image)\n",
    "img_bat = tf.expand_dims(img_arr,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef34912",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(img_bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tf.nn.softmax(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Veg/Fruit in image is {} with accuracy of {:0.2f}'.format(data_cat[np.argmax(score)],np.max(score)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a379dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Image_classify.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d192abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Image_classify.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4ed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd0f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb5402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3584e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
